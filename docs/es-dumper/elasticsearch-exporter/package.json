{
  "name": "elasticsearch-exporter",
  "description": "A utility for exporting data from one Elasticsearch cluster to another",
  "keywords": [
    "export",
    "import",
    "elastichsearch",
    "data pump"
  ],
  "homepage": "http://github.com/mallocator/Elasticsearch-Exporter",
  "bugs": {
    "url": "http://github.com/mallocator/Elasticsearch-Exporter/issues",
    "email": "mallox@pyxzl.net"
  },
  "license": "Apache 2.0",
  "version": "1.2.0",
  "author": {
    "name": "Ravi Gairola",
    "email": "mallox@pyxzl.net"
  },
  "repository": {
    "type": "git",
    "url": "http://github.com/mallocator/Elasticsearch-Exporter.git"
  },
  "files": [
    "drivers",
    "options.js",
    "exporter.js",
    "tools",
    "README.md",
    "LICENSE"
  ],
  "main": "./exporter.js",
  "bin": {
    "eexport": "tools/ex.sh"
  },
  "dependencies": {
    "nomnom": "1.6.x",
    "through": "2.3.x",
    "colors": ">=0.5.x"
  },
  "devDependencies": {
    "mocha": "1.13.x",
    "gently": "0.9.x",
    "chai": "1.8.x",
    "nock": "0.22.x"
  },
  "engine": {
    "node": ">=0.10"
  },
  "scripts": {
    "test": "mocha"
  },
  "readme": "#Elasticsearch-Exporter\n\nA small script to export data from one Elasticsearch cluster into another.\n\nFeatures:\n* Node.js based command line tool\n* Export to ElasticSearch or (compressed) flat files\n* Recreates mapping on target\n* Source data can be filtered by query\n* Specify scope as type, index or whole cluster\n* Sync Index settings along with existing mappings\n* Run in test mode without modifying any data\n\n## Usage\n\nFrom one database to another database\n```JavaScript\n// copy all indices from machine a to b\nnode exporter.js -a localhost -b foreignhost\n\n// copy entire index1 to index2 on same machine\nnode exporter.js -i index1 -j index2\n\n// copy type1 to type2 in same index\nnode exporter.js -i index -t type1 -u type2\n\n// copy type1 from index1 to type2 in index2\nnode exporter.js -i index1 -t type1 -j index2 -u type2\n\n// copy entire index1 from machine a to b\nnode exporter.js -a localhost -i index1 -b foreignhost\n\n// copy index1 from machine1 to index2 on machine2\nnode exporter.js -a localhost -i index1 -b foreignhost -j index2\n\n// only copy stuff from machine1 to machine2, that is in the query\nnode exporter.js -a localhost -b foreignhost -s '{\"bool\":{\"must\":{\"field\":{\"field1\":\"value1\"}}}}'\n\n// Do not execute any operation on machine2, just see the amount of data that would be queried\nnode exporter.js -a localhost -b foreignhost -r true\n```\n\nFrom database to file or vice versa you can use the following commands. Note that data file are now compressed by default. To disable this feature use additional flags:\n```JavaScript\n// Export to file from database\nnode exports.js -a localhost -i index1 -t type1 -g filename\n\n// Import from file to database\nnode exports.js -f filename -b foreignhost -i index2 -t type2\n\n// To override the compression for a given source file\nnode exports.js -f filename -c false -b foreignhost -j index2 -u type2\n\n// To override the compression for a target file\nnode exports.js -a localhost -i index1 -t type1 -g filename -d false\n```\n\n\nIf memory is an issue pass these parameters and the process will try to run garbage collection before reaching memory limitations\n```\nnode --nouse-idle-notification --expose-gc exporter.js ...\n```\n\nOr make use of the script in the tools folder:\n```\ntools/ex.sh ...\n```\n\n## Requirements\n\nTo run this script you will need at least node v0.10, as well as the nomnom, colors and through package installed (which will be installed automatically via npm).\n\n## Installation\n\nRun the following command in the directory where you want the tools installed\n\n\tnpm install elasticsearch-exporter --production\n\nThe required packages will be installed automatically as a dependency, you won't have to do anything else to use the tool. If you install the package with the global flag (```npm -g```) there will also be a new executable available in the system called \"eexport\".\n\n## Tests\n\nTo run the tests you must install the development dependencies along with the production dependencies\n\n\tnpm install elasticsearch-exporter\n\nAfter that you can just run ```npm test``` to see an output of all existing tests.\n\n## Changelog\n\n### 1.2.0\n* New File Layout (incompatible with 1.1.x)\n* Index settings are now also exported, when exporting in scope all or index\n* On errors the connection will be retried for fetching and writing data\n* Colors dependencies is now included explicitly\n* Project is now available from npm repo\n* Data files are now compressed by default (compressed source files are auto detected)\n* Parent directories are now created for target file if they don't exist\n* Tweaked V8 options in tools/ex.sh for better memory usage\n* Added option to mute all standard output (errors will still be displayed)\n* Tests for all operations\n\n### 1.1.4\n* ES driver can now fetch more hits per scroll request\n* File driver is now set up properly so that data is streamed much faster\n* Fixed attaching events to same file resource multiple times\n* Fixed file driver not reading entire files\n* Added percentage output to peak memory used\n* Fixed some typos in the log messages\n\n### 1.1.3\n* Fixed bug where sockets would wait forever to be released (thanks @dplate)\n* Fixed bug where the last few documents were not written to target driver (thanks @jostsg)\n* Fixed bug where null was written to the target driver as first line\n* Increased number of sockets used in es driver, so that pumping data should now be faster in many cases.\n\n### 1.1.2\n* Process will now observe available memory and wait for writes to go through before fetching more data (if gc is available).\n* Removed check for target files (which was non sense)\n\n### 1.1.1\n* Fixed a bug that would prevent the script from terminating\n* Added a test driver to figure out where certain problems are\n* Pushed dependency on node from version 0.6 to 0.10 since we're using new stream implementation\n\n### 1.1.0\n* Now supports importing/exporting into files\n* Refactored most code to be better maintainable\n* Removed some old dependencies\n\n### 1.0.0\n* First working implementation for pumping data from on database to another (or the same)\n",
  "readmeFilename": "README.md",
  "_id": "elasticsearch-exporter@1.2.0",
  "dist": {
    "shasum": "7123716a0fb42e5d09255f9e59e1db332cb457ff"
  },
  "_from": "elasticsearch-exporter@",
  "_resolved": "https://registry.npmjs.org/elasticsearch-exporter/-/elasticsearch-exporter-1.2.0.tgz"
}
